from datetime import time

import openai

from src.private.apikeys import open_ai_key

openai.api_key = open_ai_key

# Premise behind Neuron object:
# The neuron object is modeled upon a biological neuron.
# Tokens on their own do not have the complexity to represent neurons.
# Groups of tokens can be an appropriate analog for neuro-transmitters.
# Tokens are collected through the context prompt till and activation threshold is reached.
# Then GPT is forced to think about what it sees and produce a response.
# That response is then forwarded to other neurons which repeat the process.


class Neuron:
    def __init__(self, system_prompt: str, activation_thresh: int):
        self._system_prompt = system_prompt
        self._activation_thresh = activation_thresh
        # History acts as a state holder
        self.history = [{"role": "system", "content": system_prompt}]

    @property
    def sp(self):
        """
        This function returns the system prompt.
        :return: The method `sp` is returning the value of the attribute `_system_prompt` of the object that calls it.
        """
        return self._system_prompt

    @sp.setter
    def sp(self, val: str):
        """
        This is a setter method that sets the value of a private variable "_system_prompt" to the input parameter "val".

        :param val: val is a parameter that represents the value that will be assigned to the `_system_prompt` attribute of
        an object. The `self` parameter refers to the instance of the object that the method is being called on
        """
        self._system_prompt = val

    @property
    def at(self):
        """
        This function returns the activation threshold of an object.
        :return: The method `at` is returning the value of the attribute `_activation_thresh`.
        """
        return self._activation_thresh

    @at.setter
    def at(self, val: int):
        """
        This function sets the activation threshold value for an object.

        :param val: val is a parameter of type integer that represents the activation threshold value. This method sets the
        activation threshold to the value passed in as the parameter
        :type val: int
        """
        self._activation_thresh = val

    def add_context_prompt(self, context_message: str):
        """
        This function adds a context message to the history list with the role of "user".

        :param context_message: The parameter "context_message" is a string that represents the message or context that the
        user wants to add to the conversation history. This method adds the context message to the conversation history as a
        dictionary with the "role" key set to "user" and the "content" key set to the context
        :type context_message: str
        """
        # The context prompt is like dendrites accepting input
        self.history.append({"role": "user", "content": context_message})

    def think(self):
        """
        This function uses OpenAI's GPT-3.5 model to generate a response based on the conversation history provided as
        input.
        :return: the message generated by the OpenAI GPT-3.5-turbo model in response to the conversation history stored in
        `self.history`. The message is extracted from the `resp` dictionary returned by the `openai.ChatCompletion.create()`
        method, specifically from the `"message"` key of the first element in the `"choices"` list.
        """
        while True:
            try:
                resp = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=self.history
                )
            except:
                print("OpenAI had a problem.")
                time.sleep(1)
                continue
            return resp["choices"][0]["message"]

    def __call__(self):
        """
        This function returns the current output state of a neuron if the length of its history is greater than a certain
        threshold.
        :return: If the length of the `history` list is greater than the `_activation_thresh` attribute, then the `think()`
        method is called and its output is returned. Otherwise, `None` is returned.
        """
        # Calling behaves like an axon producing the current output state of the neuron
        if len(self.history) > self._activation_thresh:
            thought = self.think()
            # Clear the history and load default system prompt
            self.history = [{"role": "system", "content": self._system_prompt}]
            return thought
        return None

